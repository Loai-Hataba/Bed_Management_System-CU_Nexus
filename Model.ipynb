{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4609bb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3841f8a4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 1) Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8751d586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rows: 925\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"RFID.db\")\n",
    "\n",
    "df = pd.read_sql(\"\"\"\n",
    "SELECT \n",
    "    age, sex, bmi, diagnosis, blood_type,\n",
    "    gcs_total, wfns_grade, stopbang_score,\n",
    "    sodium, potassium, creatinine, gfr, alt, ast, bilirubin,\n",
    "    hemoglobin, wbc, platelets, blood_sugar,\n",
    "    num_medications, num_investigations, imaging_abnormal_count, comorbidity_count,\n",
    "    severity_score,\n",
    "    admission_date,\n",
    "    recovery_days\n",
    "FROM PatientFeatures\n",
    "WHERE recovery_days IS NOT NULL\n",
    "\"\"\", conn)\n",
    "\n",
    "print(\"Loaded rows:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ad1a22",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 2) Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6693d8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = [\"sex\", \"blood_type\", \"diagnosis\"]\n",
    "numeric = [c for c in df.columns if c not in categorical + [\"recovery_days\", \"admission_date\"]]\n",
    "# print(categorical)\n",
    "# print(numeric)\n",
    "# print(df.columns)\n",
    "X = df[categorical + numeric]\n",
    "y = df[\"recovery_days\"]\n",
    "\n",
    "# pipeline: one-hot encode categorical + scale numeric\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical),\n",
    "    (\"num\", StandardScaler(), numeric)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e219cc5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 3) Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "648d5865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 4.996753716518559\n",
      "R²: 0.6103936393752393\n",
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "Best parameters: {'regressor__min_samples_leaf': 20, 'regressor__max_iter': 500, 'regressor__max_depth': None, 'regressor__max_bins': 64, 'regressor__learning_rate': 0.05, 'regressor__l2_regularization': 10.0, 'regressor__early_stopping': True}\n",
      "Tuned HGB MAE: 4.638230100313117\n",
      "Tuned HGB R²: 0.6391247818799596\n"
     ]
    }
   ],
   "source": [
    "model = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", HistGradientBoostingRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"R²:\", r2_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# ---- Define hyperparameter space ----\n",
    "param_dist = {\n",
    "    \"regressor__learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "    \"regressor__max_iter\": [200, 500, 1000],              # number of boosting stages\n",
    "    \"regressor__max_depth\": [None, 5, 10, 20],\n",
    "    \"regressor__min_samples_leaf\": [20, 50, 100],         # regularization\n",
    "    \"regressor__l2_regularization\": [0.0, 0.1, 1.0, 10.0],\n",
    "    \"regressor__max_bins\": [64, 128],                    # histogram binning\n",
    "    \"regressor__early_stopping\": [True]                   # prevent overfitting\n",
    "}\n",
    "\n",
    "# ---- Randomized search ----\n",
    "random_search_hgb = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=25,              # try 25 random combos\n",
    "    cv=3,                   # 3-fold cross validation\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ---- Fit search ----\n",
    "random_search_hgb.fit(X_train, y_train)\n",
    "\n",
    "# ---- Best model ----\n",
    "best_hgb = random_search_hgb.best_estimator_\n",
    "print(\"Best parameters:\", random_search_hgb.best_params_)\n",
    "\n",
    "# ---- Evaluate on test ----\n",
    "y_pred_hgb = best_hgb.predict(X_test)\n",
    "mae_hgb = mean_absolute_error(y_test, y_pred_hgb)\n",
    "r2_hgb = r2_score(y_test, y_pred_hgb)\n",
    "print(\"Tuned HGB MAE:\", mae_hgb)\n",
    "print(\"Tuned HGB R²:\", r2_hgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "699792e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features by permutation importance:\n",
      "gcs_total: 0.3601\n",
      "diagnosis_Migraine/Headache: 0.0834\n",
      "diagnosis_Epilepsy/Seizure: 0.0796\n",
      "diagnosis_Hemorrhagic stroke: 0.0413\n",
      "severity_score: 0.0354\n",
      "diagnosis_Brain tumor: 0.0292\n",
      "diagnosis_Ischemic stroke: 0.0273\n",
      "wfns_grade: 0.0137\n",
      "diagnosis_Other: 0.0116\n",
      "creatinine: 0.0069\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# X_test should be the preprocessed features\n",
    "X_test_transformed = best_hgb.named_steps['preprocessor'].transform(X_test)\n",
    "\n",
    "result = permutation_importance(\n",
    "    best_hgb.named_steps['regressor'], \n",
    "    X_test_transformed, \n",
    "    y_test, \n",
    "    n_repeats=10, \n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Get feature names from preprocessor\n",
    "def get_feature_names(preprocessor):\n",
    "    feature_names = []\n",
    "    for name, transformer, columns in preprocessor.transformers_:\n",
    "        if name != 'remainder':\n",
    "            if hasattr(transformer, 'get_feature_names_out'):\n",
    "                names = transformer.get_feature_names_out(columns)\n",
    "            else:\n",
    "                names = columns\n",
    "            feature_names.extend(names)\n",
    "    return feature_names\n",
    "\n",
    "feature_names = get_feature_names(best_hgb.named_steps['preprocessor'])\n",
    "\n",
    "importances = result.importances_mean\n",
    "feature_importance_dict = dict(zip(feature_names, importances))\n",
    "sorted_importances = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Top 10 features by permutation importance:\")\n",
    "for feature, importance in sorted_importances[:10]:\n",
    "    print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c789769",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 4) Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fa4bdb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as model.pkl\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(model, \"model.pkl\")\n",
    "print(\"Model saved as model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a77a30",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 5) Example prediction & insert into Predictions table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "08555a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "2023-11-14\n",
      "2023-10-27 16:39:20\n",
      "2 P0001 18 2023-11-14 RF_v1.0 0.85\n",
      "Prediction inserted: 18 days, discharge 2023-11-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loaiw\\AppData\\Local\\Temp\\ipykernel_26964\\2779443234.py:21: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  print(int(row[\"admission_id\"]), row[\"patient_id\"][0],\n",
      "C:\\Users\\loaiw\\AppData\\Local\\Temp\\ipykernel_26964\\2779443234.py:27: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  \"\"\", (int(row[\"admission_id\"]), row[\"patient_id\"][0],\n"
     ]
    }
   ],
   "source": [
    "admission_id = 2  # change to a valid admission_id in your DB\n",
    "conn = sqlite3.connect(\"RFID.db\")\n",
    "\n",
    "row = pd.read_sql(f\"SELECT * FROM PatientFeatures WHERE admission_id={admission_id}\", conn)\n",
    "\n",
    "if not row.empty:\n",
    "    # drop leakage cols\n",
    "    drop_cols = [\"feature_id\",\"admission_id\",\"patient_id\",\"recovery_days\",\n",
    "                    \"discharge_date\",\"predicted_recovery_days\",\"predicted_discharge_date\",\n",
    "                    \"model_version\",\"prediction_confidence\",\"created_at\"]\n",
    "    X_new = row.drop(columns=[c for c in drop_cols if c in row.columns])\n",
    "\n",
    "    pred_days = int(model.predict(X_new)[0])\n",
    "    admission_date = pd.to_datetime(row[\"admission_date\"][0])\n",
    "    pred_discharge = (admission_date + timedelta(days=pred_days)).strftime(\"%Y-%m-%d\")\n",
    "    print(pred_days)\n",
    "    print(pred_discharge)\n",
    "    print(admission_date)\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "    INSERT INTO Predictions (admission_id, patient_id, predicted_recovery_days,\n",
    "                             predicted_discharge_date, model_version, confidence)\n",
    "    VALUES (?, ?, ?, ?, ?, ?)\n",
    "    \"\"\", (int(row[\"admission_id\"]), row[\"patient_id\"][0],\n",
    "          pred_days, pred_discharge, \"RF_v1.0\", 0.85))\n",
    "    conn.commit()\n",
    "    print(f\"Prediction inserted: {pred_days} days, discharge {pred_discharge}\")\n",
    "\n",
    "\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
